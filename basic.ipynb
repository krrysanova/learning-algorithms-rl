{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Practice with basic RL algorithms\n",
        "In this notebook I want to explore 3 basic algotithms of RL:\n",
        "\n",
        "\n",
        "*   Multi-Armed Bandits (Îµ-greedy strategy)\n",
        "*   Q-learning"
      ],
      "metadata": {
        "id": "Bmm0oB0yKfvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Armed Bandits\n",
        "You have entered a casino where there are several slot machines (bandits), each of which has a different probability of winning.\n",
        "\n",
        "You do not know which one is the winning one, so you have to experiment (try them all) and exploit (play the best one)."
      ],
      "metadata": {
        "id": "pS3n0Xp3LlBg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JGXYYz1YKfAv"
      },
      "outputs": [],
      "source": [
        "bandits = [0.1, 0.3, 0.5] #possibilities of winning with each authomat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def pull(arm_idx):\n",
        "  if random.random() <= bandits[arm_idx]:\n",
        "    return 1\n",
        "  return 0"
      ],
      "metadata": {
        "id": "6LrqGKavMQjm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "win_counts = [0, 0, 0]\n",
        "using_counts = [0, 0, 0]\n",
        "exploring_prob = 0.1\n",
        "\n",
        "for i in range(1000):\n",
        "  arm_idx = 0\n",
        "  if random.random() <= exploring_prob:\n",
        "    arm_idx = random.randint(0, 2)\n",
        "  else:\n",
        "    arm_idx = win_counts.index(max(win_counts))\n",
        "\n",
        "  win_counts[arm_idx] += pull(arm_idx)\n",
        "  using_counts[arm_idx] += 1\n",
        "\n",
        "print(\"win counts for each authomat: \", win_counts)\n",
        "print(\"using counts of each authomat: \", using_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igi5GL0WNQkt",
        "outputId": "b1020b20-3e1c-4d36-d8f7-c44d3fc72731"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "win counts for each authomat:  [4, 289, 11]\n",
            "using counts of each authomat:  [28, 945, 27]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q-learning\n",
        "\n",
        "Q-learning is a model-free reinforcement learning algorithm that allows an agent to learn the optimal action policy in the environment through trial and error.\n",
        "\n",
        "\n",
        "\n",
        "*   s (state) - the current situation of the agent in the environment\n",
        "*   a (action) - what an agent can do\n",
        "*   r (reward) - the numerical value that the agent receives for the action\n",
        "*   Q(s, a) - expected long-term reward for action a in state s\n",
        "*   policy - the agent's strategy for choosing an action in each state\n"
      ],
      "metadata": {
        "id": "ALSQ2mDFUE2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# S - start, . - free, # - wall, G - goal\n",
        "grid = [['S', '.', '.', '.'],\n",
        "        ['#', '.', '#', '.'],\n",
        "        ['.', '.', '.', '.'],\n",
        "        ['.', '.', '#', 'G']]\n",
        "\n",
        "start = (0, 0)\n",
        "goal = (3, 3)\n",
        "\n",
        "actions = ['up', 'down', 'right', 'left']\n",
        "\n",
        "# Q(s, a)\n",
        "Q = {}\n",
        "for i in range(4):\n",
        "    for j in range(4):\n",
        "        if grid[i][j] != '#':\n",
        "            Q[(i, j)] = {a: 0.0 for a in actions}"
      ],
      "metadata": {
        "id": "DmxWXXpCWD07"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlbJRfjBb9qb",
        "outputId": "7794f31d-a6c2-48a3-e053-99f278de1949"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0, 0): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (0, 1): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (0, 2): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (0, 3): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (1, 1): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (1, 3): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (2, 0): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (2, 1): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (2, 2): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (2, 3): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (3, 0): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (3, 1): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0},\n",
              " (3, 3): {'up': 0.0, 'down': 0.0, 'right': 0.0, 'left': 0.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "learning_rate = 0.2\n",
        "consideretion_of_future = 0.9\n",
        "research = 1\n",
        "research_min = 0.1\n",
        "epochs = 1000"
      ],
      "metadata": {
        "id": "wlhI7QYXZWZo"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "for i in range(epochs):\n",
        "  cur_state = start\n",
        "\n",
        "  while cur_state != goal:\n",
        "    actions = Q[cur_state]\n",
        "    if random.random() <= research:\n",
        "      action_keys = list(actions.keys())\n",
        "      a = random.choice(action_keys)\n",
        "    else:\n",
        "      a = max(actions, key=actions.get)\n",
        "\n",
        "    if (a == 'up' and cur_state[0] > 0):\n",
        "      next_state = (cur_state[0] - 1, cur_state[1])\n",
        "    elif (a == 'down' and cur_state[0] < 3):\n",
        "      next_state = (cur_state[0] + 1, cur_state[1])\n",
        "    elif (a == 'right' and cur_state[1] < 3):\n",
        "      next_state = (cur_state[0], cur_state[1] + 1)\n",
        "    elif (a == 'left' and cur_state[1] > 0):\n",
        "      next_state = (cur_state[0], cur_state[1] - 1)\n",
        "    else:\n",
        "      next_state = cur_state\n",
        "\n",
        "    if grid[next_state[0]][next_state[1]] == '#':\n",
        "        next_state = cur_state\n",
        "\n",
        "    r = 0\n",
        "\n",
        "    if grid[next_state[0]][next_state[1]] == '.':\n",
        "      r = -0.01\n",
        "    elif grid[next_state[0]][next_state[1]] == '#':\n",
        "      r = -1\n",
        "    elif grid[next_state[0]][next_state[1]] == 'G':\n",
        "      r = 1\n",
        "\n",
        "    new_actions = Q[next_state]\n",
        "    new_best_a = max(new_actions, key=new_actions.get)\n",
        "    new_best_a_value = new_actions[new_best_a]\n",
        "\n",
        "    Q[cur_state][a] = Q[cur_state][a] + learning_rate * (r + consideretion_of_future * new_best_a_value - Q[cur_state][a])\n",
        "\n",
        "    research = max(research * 0.99, research_min)\n",
        "    cur_state = next_state"
      ],
      "metadata": {
        "id": "QJT5MKx_aF2H"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur_state = start\n",
        "road = []\n",
        "road.append(cur_state)\n",
        "\n",
        "while cur_state != goal:\n",
        "  actions = Q[cur_state]\n",
        "  a = max(actions, key=actions.get)\n",
        "\n",
        "  if (a == 'up' and cur_state[0] > 0):\n",
        "      next_state = (cur_state[0] - 1, cur_state[1])\n",
        "  elif (a == 'down' and cur_state[0] < 3):\n",
        "    next_state = (cur_state[0] + 1, cur_state[1])\n",
        "  elif (a == 'right' and cur_state[1] < 3):\n",
        "    next_state = (cur_state[0], cur_state[1] + 1)\n",
        "  elif (a == 'left' and cur_state[1] > 0):\n",
        "    next_state = (cur_state[0], cur_state[1] - 1)\n",
        "  else:\n",
        "    next_state = cur_state\n",
        "\n",
        "  road.append(next_state)\n",
        "  cur_state = next_state\n",
        "\n",
        "print('Best road: ', road)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2uEfnY7kHPs",
        "outputId": "a22d7c9a-9559-4ec0-b486-5de2d877c88f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best road:  [(0, 0), (0, 1), (1, 1), (2, 1), (2, 2), (2, 3), (3, 3)]\n"
          ]
        }
      ]
    }
  ]
}